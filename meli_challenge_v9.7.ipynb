{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations, product\n",
    "from numba import njit, vectorize\n",
    "import numba as nb\n",
    "from ast import literal_eval\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones.\n",
    "def load_ib2():\n",
    "    name = 'ib'\n",
    "    V = pd.read_csv(name+'.csv', sep=';')\n",
    "    V = pd.merge(V, \n",
    "                 ITEM_DATA.loc[:,['item_id', 'domain_code', 'mexico']], \n",
    "                 how='left', \n",
    "                 left_on='ib', \n",
    "                 right_on='item_id').drop(columns=['item_id'])\n",
    "    return np.array(V['ib']), np.array(V['domain_code']), np.array(V['mexico'])\n",
    "\n",
    "def load_chosen_predictors(folder, predictors=[], nan_treat=False, k=10):\n",
    "    PRED = {}\n",
    "    pred = {}\n",
    "    PRED1 = {}\n",
    "    pred1 = {}\n",
    "    PRED2 = {}\n",
    "    pred2 = {}\n",
    "    for fname in tqdm(os.listdir(folder)):\n",
    "        name = fname.replace('_r413162','').replace('.csv','')\n",
    "        if name in predictors or len(predictors) == 0:\n",
    "            if '_r413162' in fname:\n",
    "                PRED[name] = pd.read_csv(folder+'/'+fname)\n",
    "                pred[name] = np.array(PRED[name])\n",
    "                pred[name] = pred[name][:,1:]\n",
    "            else:\n",
    "                PRED[name] = pd.read_csv(folder+'/'+fname, sep=';')\n",
    "                pred[name] = np.array(PRED[name])\n",
    "            if nan_treat:\n",
    "                pred[name][np.isnan(pred[name])] = -1\n",
    "            for j, p in enumerate(['pred'+str(i) for i in range(k)]):\n",
    "                if j == 0:\n",
    "                    PRED1[name] = pd.merge(PRED[name][p], \n",
    "                        ITEM_DATA.loc[:,['item_id', 'domain_code']],\n",
    "                        how='left',\n",
    "                        left_on=p,\n",
    "                        right_on='item_id').drop(columns=[p, 'item_id'])\n",
    "                    PRED2[name] = pd.merge(PRED[name][p], \n",
    "                        ITEM_DATA.loc[:,['item_id', 'mexico']],\n",
    "                        how='left',\n",
    "                        left_on=p,\n",
    "                        right_on='item_id').drop(columns=[p, 'item_id'])\n",
    "                else:\n",
    "                    TEMP = pd.merge(PRED[name][p], \n",
    "                        ITEM_DATA.loc[:,['item_id', 'domain_code']],\n",
    "                        how='left',\n",
    "                        left_on=p,\n",
    "                        right_on='item_id').drop(columns=[p, 'item_id'])\n",
    "                    TEMP1 = pd.merge(PRED[name][p], \n",
    "                        ITEM_DATA.loc[:,['item_id', 'mexico']],\n",
    "                        how='left',\n",
    "                        left_on=p,\n",
    "                        right_on='item_id').drop(columns=[p, 'item_id'])\n",
    "                    PRED1[name] = pd.concat([PRED1[name], TEMP], axis=1)\n",
    "                    PRED2[name] = pd.concat([PRED2[name], TEMP1], axis=1)\n",
    "                PRED1[name].loc[PRED1[name]['domain_code'].isnull(), 'domain_code'] = -1\n",
    "                PRED1[name] = PRED1[name].rename(columns={'domain_code': p})\n",
    "                #PRED2[name].loc[PRED2[name]['mexico'].isnull(), 'mexico'] = False\n",
    "                PRED2[name] = PRED2[name].rename(columns={'mexico': p})\n",
    "            PRED1[name] = PRED1[name].astype('int64')\n",
    "            pred1[name] = np.array(PRED1[name])\n",
    "            #PRED2[name] = PRED2[name].astype('bool')\n",
    "            pred2[name] = np.array(PRED2[name])\n",
    "    return PRED, pred, PRED1, pred1, PRED2, pred2\n",
    "\n",
    "def load_chosen_predictors_pred(folder, predictors=[], nan_treat=False, k=10):\n",
    "    PRED = {}\n",
    "    pred = {}\n",
    "    for fname in tqdm(os.listdir(folder)):\n",
    "        name = fname.replace('_pred','').replace('.csv','')\n",
    "        if name in predictors or len(predictors) == 0:\n",
    "            PRED[name] = pd.read_csv(folder+'/'+fname, sep=';')\n",
    "            pred[name] = np.array(PRED[name])\n",
    "            if nan_treat:\n",
    "                pred[name][np.isnan(pred[name])] = -1\n",
    "    return PRED, pred\n",
    "\n",
    "def get_doms_and_mket(Y_TEST, k=10):\n",
    "    for j, p in enumerate(['pred'+str(i) for i in range(k)]):\n",
    "        if j == 0:\n",
    "            Y_TEST_DO = pd.merge(Y_TEST[p], \n",
    "                ITEM_DATA.loc[:,['item_id', 'domain_code']],\n",
    "                how='left',\n",
    "                left_on=p,\n",
    "                right_on='item_id').drop(columns=[p, 'item_id'])\n",
    "            Y_TEST_MA = pd.merge(Y_TEST[p], \n",
    "                ITEM_DATA.loc[:,['item_id', 'mexico']],\n",
    "                how='left',\n",
    "                left_on=p,\n",
    "                right_on='item_id').drop(columns=[p, 'item_id'])\n",
    "        else:\n",
    "            TEMP = pd.merge(Y_TEST[p], \n",
    "                ITEM_DATA.loc[:,['item_id', 'domain_code']],\n",
    "                how='left',\n",
    "                left_on=p,\n",
    "                right_on='item_id').drop(columns=[p, 'item_id'])\n",
    "            TEMP1 = pd.merge(Y_TEST[p], \n",
    "                ITEM_DATA.loc[:,['item_id', 'mexico']],\n",
    "                how='left',\n",
    "                left_on=p,\n",
    "                right_on='item_id').drop(columns=[p, 'item_id'])\n",
    "            Y_TEST_DO = pd.concat([Y_TEST_DO, TEMP], axis=1)\n",
    "            Y_TEST_MA = pd.concat([Y_TEST_MA, TEMP1], axis=1)\n",
    "        Y_TEST_DO.loc[Y_TEST_DO['domain_code'].isnull(), 'domain_code'] = -1\n",
    "        Y_TEST_DO = Y_TEST_DO.rename(columns={'domain_code': p})\n",
    "        Y_TEST_MA = Y_TEST_MA.rename(columns={'mexico': p})\n",
    "    Y_TEST_DO = Y_TEST_DO.astype('int64')\n",
    "    y_test_do = np.array(Y_TEST_DO)\n",
    "    y_test_ma = np.array(Y_TEST_MA)\n",
    "    return Y_TEST_DO, y_test_do, Y_TEST_MA, y_test_ma\n",
    "\n",
    "def get_doms(ii):\n",
    "    II = pd.DataFrame(ii, columns=['items'])\n",
    "    II_DO = pd.merge(II['items'], \n",
    "        ITEM_DATA.loc[:,['item_id', 'domain_code']],\n",
    "        how='left',\n",
    "        left_on='items',\n",
    "        right_on='item_id').drop(columns=['items', 'item_id'])\n",
    "    II_DO.loc[II_DO['domain_code'].isnull(), 'domain_code'] = -1\n",
    "    II_DO = II_DO.rename(columns={'domain_code': 'doms'})\n",
    "    return np.array(II_DO).reshape(-1)\n",
    "\n",
    "def eval_feature(a):\n",
    "    e = 0\n",
    "    for i in range(a.size):\n",
    "        e += a[i] / np.log(i + 2)\n",
    "    return e\n",
    "\n",
    "@njit(parallel=True)\n",
    "def get_y_hat(ii, rr, k=10):\n",
    "    target = np.unique(ii)\n",
    "    size = target.size\n",
    "    temp = np.zeros(size)\n",
    "    for i in range(size):\n",
    "        #temp[i] = rr[ii == target[i]].max()\n",
    "        temp[i] = rr[ii == target[i]].sum()\n",
    "    return target[temp.argsort()][-k:]\n",
    "\n",
    "@njit(parallel=True)\n",
    "def compare(a, b):\n",
    "    return a == b\n",
    "\n",
    "@vectorize(nopython=True, target='parallel')\n",
    "def less_than_13(a):\n",
    "    a[a > 12] == 12\n",
    "    return a\n",
    "\n",
    "def gen_sales(y_hat, cdom, cmket):\n",
    "    if cdom == -1:\n",
    "        cdom = 2082\n",
    "    if cmket == 1:\n",
    "        target = brs[brs_do == cdom]\n",
    "    else:\n",
    "        target = mex[mex_do == cdom]\n",
    "    return target[np.logical_not(np.isin(target, y_hat, assume_unique=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_DATA = pd.read_csv('item_data.csv', sep=';')\n",
    "ITEM_DATA.loc[ITEM_DATA['product_id'] == 0, 'product_id'] = -1\n",
    "ITEM_DATA['domain_code'], domain_uniques = pd.factorize(ITEM_DATA['domain_id'], sort=True)\n",
    "ITEM_DATA['category_code'], category_uniques = pd.factorize(ITEM_DATA['category_id'], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib, ib_do, ib_ma = load_ib2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfdde29cc76422d88d91a479e7586ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=56), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#chosen_predictors = ['dim_bc',\n",
    "#                     'dim_liv',\n",
    "#                     'dim_miv',\n",
    "#                     'dim_odom_13',\n",
    "#                     'dim_opro_13',\n",
    "#                     'dim_ocat_13',\n",
    "#                     'dim_odom_16',\n",
    "#                     'dim_opro_16',\n",
    "#                     'dim_ocat_16',\n",
    "#                     'dim_sdom_31',\n",
    "#                     'dim_spro_31',\n",
    "#                     'dim_scat_31',\n",
    "#                     'dim_sdom_13',\n",
    "#                     'dim_spro_13',\n",
    "#                     'dim_scat_13',\n",
    "#                     'dim_tbd',\n",
    "#                     'dim_tbd2',\n",
    "#                     'dim_tbc',\n",
    "#                     'dim_tbc2',\n",
    "#                     'dim_tbp',\n",
    "#                     'dim_tbp2',\n",
    "#                     'dim_vc',\n",
    "#                     'dim_sss']\n",
    "\n",
    "chosen_predictors = ['dim_miv', 'dim_tbc', 'dim_liv', 'dim_ocat_16', 'dim_bc', 'dim_sss', 'dim_tbp', 'dim_vc']\n",
    "\n",
    "PRED, pred, PRED1, pred1, PRED2, pred2 = load_chosen_predictors('C:/data/meli_challenge/predictors', chosen_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split.\n",
    "main_index = [x for x in range(len(ib))]\n",
    "idx_train, idx_test = train_test_split(main_index, test_size=0.5, random_state=45)\n",
    "idx_train = sorted(idx_train)\n",
    "idx_test = sorted(idx_test)\n",
    "ib_train = ib[idx_train]\n",
    "ib_test = ib[idx_test]\n",
    "ib_do_train = ib_do[idx_train]\n",
    "ib_do_test = ib_do[idx_test]\n",
    "ib_ma_train = ib_ma[idx_train]\n",
    "ib_ma_test = ib_ma[idx_test]\n",
    "pred_train = {}\n",
    "pred1_train = {}\n",
    "pred2_train = {}\n",
    "pred_test = {}\n",
    "for f in chosen_predictors:\n",
    "    pred_train[f] = pred[f][idx_train]\n",
    "    pred1_train[f] = pred1[f][idx_train]\n",
    "    pred2_train[f] = pred2[f][idx_train]\n",
    "    pred_test[f] = pred[f][idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mercado y dominio visitado.\n",
    "DFF = pd.read_csv('dff.csv', sep=';')\n",
    "mket_train = np.array(DFF['mercado'])[idx_train]\n",
    "mket_test = np.array(DFF['mercado'])[idx_test]\n",
    "DMV = pd.read_csv('dmv.csv', sep=';')\n",
    "dom_train = np.array(DMV['vdomain']).reshape(-1)[idx_train]\n",
    "dom_test = np.array(DMV['vdomain']).reshape(-1)[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tops.\n",
    "top_mex = [716822, 429798, 1303554, 806452, 1767506, 1276232, 1796243, 795217, 1930193, 1139737]\n",
    "top_brs = [1587422, 1803710, 10243, 548905, 1906937, 1361154, 1716388, 725371, 859574, 290755]\n",
    "MEX = pd.read_csv('mex.csv', sep=';')\n",
    "BRS = pd.read_csv('brs.csv', sep=';')\n",
    "mex = np.array(MEX['item'])\n",
    "brs = np.array(BRS['item'])\n",
    "mex_do = np.array(MEX['domain'])\n",
    "brs_do = np.array(BRS['domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Clusters.\n",
    "clusters = pd.read_csv('clusters_maradona_v2.csv', sep=';')\n",
    "train_test = pd.read_csv('meli_segment_v2.csv', sep=';')\n",
    "clusters = pd.concat([clusters['cs_a3'], train_test], axis=1)\n",
    "clusters = clusters.loc[clusters['segment'] == 'train']\n",
    "cluster = np.array(clusters['cs_a3']).astype('int32')\n",
    "cluster_train = cluster[idx_train]\n",
    "cluster_test = cluster[idx_test]\n",
    "cl_train = np.unique(cluster_train, return_counts=True)\n",
    "cl_test = np.unique(cluster_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trampa cluster.\n",
    "#clusters = pd.read_csv('dfs.csv', sep=';')\n",
    "#clusters['segmento'] = 0\n",
    "#clusters.loc[clusters['v_len'] != 0, 'segmento'] = 1\n",
    "#cluster = np.array(clusters['segmento']).astype('int32')\n",
    "#cluster_train1 = cluster[idx_train]\n",
    "#cluster_test1 = cluster[idx_test]\n",
    "#cl_train1 = np.unique(cluster_train1, return_counts=True)\n",
    "#cl_test1 = np.unique(cluster_test1, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850d987889a64bcc8bfbfb97fcc4c3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=75), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Grilla.\n",
    "ibr = ib_train.reshape(ib_train.size,1).repeat(10, axis=1)\n",
    "ibr_do = ib_do_train.reshape(ib_do_train.size,1).repeat(10, axis=1)\n",
    "ibr_ma = ib_ma_train.reshape(ib_ma_train.size,1).repeat(10, axis=1)\n",
    "\n",
    "grilla = {}\n",
    "for k in tqdm(range(len(cl_train[0]))):\n",
    "    eval = {}\n",
    "    eval1 = {}\n",
    "    eval2 = {}\n",
    "    performance = {}\n",
    "    feat_perf = {}\n",
    "    for i in pred:\n",
    "            eval[i] = ibr[cluster_train == cl_train[0][k]] == pred_train[i][cluster_train == cl_train[0][k]]\n",
    "            eval1[i] = ibr_do[cluster_train == cl_train[0][k]] == pred1_train[i][cluster_train == cl_train[0][k]]\n",
    "            eval2[i] = ibr_ma[cluster_train == cl_train[0][k]] == pred2_train[i][cluster_train == cl_train[0][k]]\n",
    "            performance[i] = eval[i].mean(axis=0) + (eval1[i] * eval2[i]).mean(axis=0) / 12\n",
    "            feat_perf.update({i: performance[i]})\n",
    "    grilla.update({cl_train[0][k]: feat_perf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance.\n",
    "eval = {}\n",
    "eval1 = {}\n",
    "eval2 = {}\n",
    "performance = {}\n",
    "feat_perf = {}\n",
    "ibr = ib_train.reshape(ib_train.size,1).repeat(10, axis=1)\n",
    "ibr_do = ib_do_train.reshape(ib_do_train.size,1).repeat(10, axis=1)\n",
    "ibr_ma = ib_ma_train.reshape(ib_ma_train.size,1).repeat(10, axis=1)\n",
    "\n",
    "for i in pred_train:\n",
    "        eval[i] = ibr == pred_train[i]\n",
    "        eval1[i] = ibr_do == pred1_train[i]\n",
    "        eval2[i] = ibr_ma == pred2_train[i]\n",
    "        performance[i] = eval[i].mean(axis=0) + (eval1[i] * eval2[i]).mean(axis=0) / 12\n",
    "        feat_perf.update({i: performance[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Versiones. VER BIEN AL EMPEZAR DE NUEVO.\n",
    "grupoA = list(chosen_predictors)\n",
    "grupoB = []\n",
    "c_versiones = [[x] for x in grupoA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dim_miv',\n",
       "  'dim_tbc',\n",
       "  'dim_liv',\n",
       "  'dim_sss',\n",
       "  'dim_vc',\n",
       "  'dim_ocat_16',\n",
       "  'dim_tbp',\n",
       "  'dim_bc']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Versiones.\n",
    "#grupoA = ['dim_bc',\n",
    "#         'dim_odom_13',\n",
    "#         'dim_opro_13',\n",
    "#         'dim_ocat_13',\n",
    "#         'dim_odom_16',\n",
    "#         'dim_opro_16',\n",
    "#         'dim_ocat_16',\n",
    "#         'dim_sdom_31',\n",
    "#         'dim_spro_31',\n",
    "#         'dim_scat_31',\n",
    "#         'dim_sdom_13',\n",
    "#         'dim_spro_13',\n",
    "#         'dim_scat_13',\n",
    "#         'dim_tbd',\n",
    "#         'dim_tbd2',\n",
    "#         'dim_tbc2',\n",
    "#         'dim_tbp',\n",
    "#         'dim_tbp2',\n",
    "#         'dim_vc',\n",
    "#         'dim_sss']\n",
    "\n",
    "grupoA = ['dim_bc']\n",
    "\n",
    "#grupoB = ['dim_miv', 'dim_tbc', 'dim_liv']\n",
    "\n",
    "grupoB = ['dim_miv', 'dim_tbc', 'dim_liv', 'dim_sss', 'dim_vc', 'dim_ocat_16', 'dim_tbp']\n",
    "\n",
    "c_versiones = []\n",
    "for i in grupoA:\n",
    "    c_versiones.append(grupoB + [i]) \n",
    "    \n",
    "c_versiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37951e92d77440e8952615c6b2056edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614cc9e5eb3c421ba6b0aafc8ac6c221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=206582), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['dim_miv', 'dim_tbc', 'dim_liv', 'dim_sss', 'dim_vc', 'dim_ocat_16', 'dim_tbp', 'dim_bc']\n",
      "0.2893094811953384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicción.\n",
    "versiones = []\n",
    "k = 10\n",
    "nDGC_version = []\n",
    "max_nDCG = 0\n",
    "last_nDCG = -1\n",
    "\n",
    "while len(grupoA) > 0 and max_nDCG > last_nDCG:\n",
    "    \n",
    "    last_nDCG = max_nDCG\n",
    "    max_nDCG = None\n",
    "    for v in tqdm(c_versiones):\n",
    "        c_feature = v[-1]\n",
    "        \n",
    "        y_test = []\n",
    "        for i in tqdm(range(ib_test.size)):\n",
    "            ccluster = cluster_test[i]\n",
    "            cdom = dom_test[i]\n",
    "            cmket = mket_test[i]\n",
    "            for j, f in enumerate(v):\n",
    "                if ccluster in grilla:\n",
    "                    cref = grilla[ccluster][f]\n",
    "                else:\n",
    "                    alt_cluster = [x for x in grilla if abs(x - ccluster) == min([abs(x - ccluster) for x in grilla])][0]\n",
    "                    cref = grilla[alt_cluster][f]\n",
    "                citems = pred_test[f][i]\n",
    "                mask = (cref > 0) & (citems >= 0)\n",
    "                cref = cref[mask]\n",
    "                citems = citems[mask]\n",
    "                if j == 0:\n",
    "                    ranks = cref\n",
    "                    items = citems\n",
    "                else:\n",
    "                    ranks = np.concatenate([ranks, cref])\n",
    "                    items = np.concatenate([items, citems])\n",
    "            y_hat = list(get_y_hat(items, ranks)[::-1])\n",
    "            if len(y_hat) < k:\n",
    "                size = k - len(y_hat)\n",
    "                ext = list(gen_sales(y_hat, cdom, cmket)[:size])\n",
    "                y_hat.extend(ext)\n",
    "                if len(y_hat) < k:\n",
    "                    size = k - len(y_hat)\n",
    "                    if cmket == 1:\n",
    "                        ext = [x for x in top_mex if x not in y_hat][:size]\n",
    "                    else:\n",
    "                        ext = [x for x in top_brs if x not in y_hat][:size]\n",
    "                    y_hat.extend(ext)\n",
    "            y_test.append(y_hat)\n",
    "\n",
    "        Y_TEST = pd.DataFrame(y_test, columns=['pred'+str(i) for i in range(k)])\n",
    "        Y_TEST_DO, y_test_do, Y_TEST_MA, y_test_ma = get_doms_and_mket(Y_TEST)\n",
    "        cond1 = compare(np.array(y_test), ib_test.reshape(ib_test.size,1).repeat(10, axis=1))\n",
    "        cond2 = compare(y_test_do, ib_do_test.reshape(ib_do_test.size,1).repeat(10, axis=1))\n",
    "        cond3 = y_test_ma == ib_ma_test.reshape(ib_ma_test.size,1).repeat(10, axis=1)\n",
    "        numerador = cond1 * 12 + cond2 * cond3\n",
    "        numerador[numerador > 12] = 12\n",
    "\n",
    "        lns = {0: np.log(2),\n",
    "                1: np.log(3),\n",
    "                2: np.log(4),\n",
    "                3: np.log(5),\n",
    "                4: np.log(6),\n",
    "                5: np.log(7),\n",
    "                6: np.log(8),\n",
    "                7: np.log(9),\n",
    "                8: np.log(10),\n",
    "                9: np.log(11)}\n",
    "\n",
    "        for h in range(10):\n",
    "            if h == 0:\n",
    "                ideal = 12 / lns[h]\n",
    "            else:\n",
    "                ideal = ideal + 1 / lns[h]\n",
    "\n",
    "        denominador = np.ones_like(numerador)       \n",
    "        denominador = denominador * np.array(list(lns.values()))\n",
    "\n",
    "        DCG = numerador / denominador\n",
    "        DCG = DCG.sum(axis=1)\n",
    "\n",
    "        iDCG = np.ones_like(DCG) * ideal\n",
    "        nDCG = DCG / iDCG\n",
    "        nDGC_version.append({'estructura': v, 'performance': nDCG.mean(), 'performance_puntual': nDCG})\n",
    "        print(v)\n",
    "        print(nDCG.mean())\n",
    "                \n",
    "        #Selección.\n",
    "        if max_nDCG:\n",
    "            if nDCG.mean() > max_nDCG:\n",
    "                max_nDCG = nDCG.mean() \n",
    "                s_feature = c_feature\n",
    "        else:\n",
    "            max_nDCG = nDCG.mean()\n",
    "            s_feature = c_feature\n",
    "            \n",
    "    grupoA.remove(s_feature)\n",
    "    grupoB.append(s_feature)\n",
    "    \n",
    "    versiones += c_versiones\n",
    "    c_versiones = []\n",
    "    for i in grupoA:\n",
    "        c_versiones.append(grupoB + [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSIONES = pd.DataFrame(versiones)\n",
    "VERSIONES.to_csv('versiones_29-11-20_v2.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2895673580691889"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Anterior: 0.28953421814349656. Último: 0.2895673580691889.\n",
    "seleccion_modelos = pd.DataFrame(np.array([x['performance_puntual'] for x in nDGC_version]).transpose())\n",
    "seleccion_modelos = pd.concat([seleccion_modelos, pd.DataFrame(cluster_test, columns=['cluster'])], axis=1)\n",
    "a = seleccion_modelos.groupby(['cluster']).mean().max(axis=1)\n",
    "b = seleccion_modelos.groupby(['cluster']).count().max(axis=1)\n",
    "c = seleccion_modelos.groupby(['cluster']).count().max(axis=1).sum()\n",
    "sum((a * b) / c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "send = seleccion_modelos.groupby(['cluster']).mean()\n",
    "send.to_csv('seleccion_modelos_29-11-20_v2.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27575719113402736"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seleccion_modelos = pd.DataFrame(np.array([x['performance_puntual'] for x in nDGC_version]).transpose())\n",
    "seleccion_modelos = pd.concat([seleccion_modelos, pd.DataFrame(cluster_test1, columns=['cluster'])], axis=1)\n",
    "a = seleccion_modelos.groupby(['cluster']).mean().max(axis=1)\n",
    "b = seleccion_modelos.groupby(['cluster']).count().max(axis=1)\n",
    "c = seleccion_modelos.groupby(['cluster']).count().max(axis=1).sum()\n",
    "sum((a * b) / c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.180681</td>\n",
       "      <td>0.179144</td>\n",
       "      <td>0.175962</td>\n",
       "      <td>0.180915</td>\n",
       "      <td>0.179230</td>\n",
       "      <td>0.176360</td>\n",
       "      <td>0.181129</td>\n",
       "      <td>0.179322</td>\n",
       "      <td>0.176048</td>\n",
       "      <td>0.180868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181307</td>\n",
       "      <td>0.178629</td>\n",
       "      <td>0.182209</td>\n",
       "      <td>0.180736</td>\n",
       "      <td>0.178933</td>\n",
       "      <td>0.181717</td>\n",
       "      <td>0.181104</td>\n",
       "      <td>0.181592</td>\n",
       "      <td>0.183598</td>\n",
       "      <td>0.182152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.036731</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051158</td>\n",
       "      <td>0.051158</td>\n",
       "      <td>0.051158</td>\n",
       "      <td>0.051158</td>\n",
       "      <td>0.051158</td>\n",
       "      <td>0.051158</td>\n",
       "      <td>0.051158</td>\n",
       "      <td>0.051158</td>\n",
       "      <td>0.051158</td>\n",
       "      <td>0.051158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>0.236685</td>\n",
       "      <td>0.229413</td>\n",
       "      <td>0.240406</td>\n",
       "      <td>0.236478</td>\n",
       "      <td>0.229525</td>\n",
       "      <td>0.240757</td>\n",
       "      <td>0.236464</td>\n",
       "      <td>0.229455</td>\n",
       "      <td>0.239750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240914</td>\n",
       "      <td>0.238081</td>\n",
       "      <td>0.242812</td>\n",
       "      <td>0.239858</td>\n",
       "      <td>0.238052</td>\n",
       "      <td>0.241498</td>\n",
       "      <td>0.238729</td>\n",
       "      <td>0.239422</td>\n",
       "      <td>0.240870</td>\n",
       "      <td>0.242207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.223538</td>\n",
       "      <td>0.219373</td>\n",
       "      <td>0.217434</td>\n",
       "      <td>0.221392</td>\n",
       "      <td>0.219709</td>\n",
       "      <td>0.218144</td>\n",
       "      <td>0.222369</td>\n",
       "      <td>0.219819</td>\n",
       "      <td>0.217139</td>\n",
       "      <td>0.221679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224699</td>\n",
       "      <td>0.222912</td>\n",
       "      <td>0.225466</td>\n",
       "      <td>0.225459</td>\n",
       "      <td>0.223828</td>\n",
       "      <td>0.226380</td>\n",
       "      <td>0.224836</td>\n",
       "      <td>0.224684</td>\n",
       "      <td>0.227236</td>\n",
       "      <td>0.225665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.309294</td>\n",
       "      <td>0.310614</td>\n",
       "      <td>0.304315</td>\n",
       "      <td>0.313609</td>\n",
       "      <td>0.310420</td>\n",
       "      <td>0.304573</td>\n",
       "      <td>0.314263</td>\n",
       "      <td>0.310081</td>\n",
       "      <td>0.303378</td>\n",
       "      <td>0.313007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313917</td>\n",
       "      <td>0.313799</td>\n",
       "      <td>0.315113</td>\n",
       "      <td>0.311354</td>\n",
       "      <td>0.312996</td>\n",
       "      <td>0.311378</td>\n",
       "      <td>0.312969</td>\n",
       "      <td>0.313468</td>\n",
       "      <td>0.313102</td>\n",
       "      <td>0.314885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.341468</td>\n",
       "      <td>0.393540</td>\n",
       "      <td>0.398557</td>\n",
       "      <td>0.395756</td>\n",
       "      <td>0.341073</td>\n",
       "      <td>0.398557</td>\n",
       "      <td>0.395756</td>\n",
       "      <td>0.398557</td>\n",
       "      <td>0.398557</td>\n",
       "      <td>0.398557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398672</td>\n",
       "      <td>0.398672</td>\n",
       "      <td>0.398672</td>\n",
       "      <td>0.398672</td>\n",
       "      <td>0.398672</td>\n",
       "      <td>0.398672</td>\n",
       "      <td>0.398672</td>\n",
       "      <td>0.398672</td>\n",
       "      <td>0.398672</td>\n",
       "      <td>0.398672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.283041</td>\n",
       "      <td>0.277406</td>\n",
       "      <td>0.102807</td>\n",
       "      <td>0.277406</td>\n",
       "      <td>0.348265</td>\n",
       "      <td>0.104993</td>\n",
       "      <td>0.359259</td>\n",
       "      <td>0.277406</td>\n",
       "      <td>0.102693</td>\n",
       "      <td>0.277406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302672</td>\n",
       "      <td>0.303632</td>\n",
       "      <td>0.302672</td>\n",
       "      <td>0.302672</td>\n",
       "      <td>0.302672</td>\n",
       "      <td>0.302672</td>\n",
       "      <td>0.313779</td>\n",
       "      <td>0.302321</td>\n",
       "      <td>0.323078</td>\n",
       "      <td>0.312355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6    \\\n",
       "cluster                                                                         \n",
       "0        0.180681  0.179144  0.175962  0.180915  0.179230  0.176360  0.181129   \n",
       "1        0.036731  0.003379  0.003379  0.003379  0.003379  0.003379  0.003379   \n",
       "2        0.234303  0.236685  0.229413  0.240406  0.236478  0.229525  0.240757   \n",
       "3        0.223538  0.219373  0.217434  0.221392  0.219709  0.218144  0.222369   \n",
       "4        0.309294  0.310614  0.304315  0.313609  0.310420  0.304573  0.314263   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "248      0.341468  0.393540  0.398557  0.395756  0.341073  0.398557  0.395756   \n",
       "249      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "252      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "253      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "255      0.283041  0.277406  0.102807  0.277406  0.348265  0.104993  0.359259   \n",
       "\n",
       "              7         8         9    ...       95        96        97   \\\n",
       "cluster                                ...                                 \n",
       "0        0.179322  0.176048  0.180868  ...  0.181307  0.178629  0.182209   \n",
       "1        0.003379  0.003379  0.003379  ...  0.051158  0.051158  0.051158   \n",
       "2        0.236464  0.229455  0.239750  ...  0.240914  0.238081  0.242812   \n",
       "3        0.219819  0.217139  0.221679  ...  0.224699  0.222912  0.225466   \n",
       "4        0.310081  0.303378  0.313007  ...  0.313917  0.313799  0.315113   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "248      0.398557  0.398557  0.398557  ...  0.398672  0.398672  0.398672   \n",
       "249      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "252      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "253      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "255      0.277406  0.102693  0.277406  ...  0.302672  0.303632  0.302672   \n",
       "\n",
       "              98        99        100       101       102       103       104  \n",
       "cluster                                                                        \n",
       "0        0.180736  0.178933  0.181717  0.181104  0.181592  0.183598  0.182152  \n",
       "1        0.051158  0.051158  0.051158  0.051158  0.051158  0.051158  0.051158  \n",
       "2        0.239858  0.238052  0.241498  0.238729  0.239422  0.240870  0.242207  \n",
       "3        0.225459  0.223828  0.226380  0.224836  0.224684  0.227236  0.225665  \n",
       "4        0.311354  0.312996  0.311378  0.312969  0.313468  0.313102  0.314885  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "248      0.398672  0.398672  0.398672  0.398672  0.398672  0.398672  0.398672  \n",
       "249      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "252      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "253      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "255      0.302672  0.302672  0.302672  0.313779  0.302321  0.323078  0.312355  \n",
       "\n",
       "[252 rows x 105 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = np.array([x['performance_puntual'] for x in nDGC_version]).transpose()\n",
    "inventario = {}\n",
    "for c in np.unique(cluster_test):\n",
    "    midx = modelos[cluster_test == c, :].mean(axis=0).argmax()\n",
    "    inventario.update({c: {'v_id': midx, 'v_desc': versiones[midx]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f3eb2bae6540e7b273eebf0b09233c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=206582), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['dim_miv', 'dim_tbc', 'dim_liv', 'dim_sss', 'dim_vc', 'dim_ocat_16', 'dim_tbp', 'dim_bc', 'dim_opro_16']\n",
      "0.2895342181434993\n"
     ]
    }
   ],
   "source": [
    "#Predicción post.\n",
    "k = 10\n",
    "\n",
    "y_test = []\n",
    "for i in tqdm(range(ib_test.size)):\n",
    "    ccluster = cluster_test[i]\n",
    "    #ccluster1 = cluster_test1[i]\n",
    "    cdom = dom_test[i]\n",
    "    cmket = mket_test[i]\n",
    "    if ccluster in inventario:\n",
    "        v = inventario[ccluster]['v_desc']\n",
    "        #v = ['dim_bc', 'dim_liv', 'dim_miv', 'dim_ocat_16', 'dim_tbc', 'dim_tbc2', 'dim_tbp']\n",
    "    else:\n",
    "        alt_cluster = [x for x in list(inventario) if abs(x - ccluster) == min([abs(x - ccluster) for x in list(inventario)])][0]\n",
    "        v = inventario[alt_cluster]['v_desc']\n",
    "        #v = ['dim_bc', 'dim_liv', 'dim_miv', 'dim_ocat_16', 'dim_tbc', 'dim_tbc2', 'dim_tbp']\n",
    "    for j, f in enumerate(v):\n",
    "        if ccluster in grilla:\n",
    "            cref = grilla[ccluster][f]\n",
    "        else:\n",
    "            alt_cluster = [x for x in grilla if abs(x - ccluster) == min([abs(x - ccluster) for x in grilla])][0]\n",
    "            cref = grilla[alt_cluster][f]\n",
    "        citems = pred_test[f][i]\n",
    "        mask = (cref > 0) & (citems >= 0)\n",
    "        cref = cref[mask]\n",
    "        citems = citems[mask]\n",
    "        if j == 0:\n",
    "            ranks = cref\n",
    "            items = citems\n",
    "        else:\n",
    "            ranks = np.concatenate([ranks, cref])\n",
    "            items = np.concatenate([items, citems])\n",
    "    y_hat = list(get_y_hat(items, ranks)[::-1])\n",
    "    if len(y_hat) < k:\n",
    "        size = k - len(y_hat)\n",
    "        ext = list(gen_sales(y_hat, cdom, cmket)[:size])\n",
    "        y_hat.extend(ext)\n",
    "        if len(y_hat) < k:\n",
    "            size = k - len(y_hat)\n",
    "            if cmket == 1:\n",
    "                ext = [x for x in top_mex if x not in y_hat][:size]\n",
    "            else:\n",
    "                ext = [x for x in top_brs if x not in y_hat][:size]\n",
    "            y_hat.extend(ext)\n",
    "    y_test.append(y_hat)\n",
    "\n",
    "Y_TEST = pd.DataFrame(y_test, columns=['pred'+str(i) for i in range(k)])\n",
    "Y_TEST_DO, y_test_do, Y_TEST_MA, y_test_ma = get_doms_and_mket(Y_TEST)\n",
    "cond1 = compare(np.array(y_test), ib_test.reshape(ib_test.size,1).repeat(10, axis=1))\n",
    "cond2 = compare(y_test_do, ib_do_test.reshape(ib_do_test.size,1).repeat(10, axis=1))\n",
    "cond3 = y_test_ma == ib_ma_test.reshape(ib_ma_test.size,1).repeat(10, axis=1)\n",
    "numerador = cond1 * 12 + cond2 * cond3\n",
    "numerador[numerador > 12] = 12\n",
    "\n",
    "lns = {0: np.log(2),\n",
    "        1: np.log(3),\n",
    "        2: np.log(4),\n",
    "        3: np.log(5),\n",
    "        4: np.log(6),\n",
    "        5: np.log(7),\n",
    "        6: np.log(8),\n",
    "        7: np.log(9),\n",
    "        8: np.log(10),\n",
    "        9: np.log(11)}\n",
    "\n",
    "for h in range(10):\n",
    "    if h == 0:\n",
    "        ideal = 12 / lns[h]\n",
    "    else:\n",
    "        ideal = ideal + 1 / lns[h]\n",
    "\n",
    "denominador = np.ones_like(numerador)       \n",
    "denominador = denominador * np.array(list(lns.values()))\n",
    "\n",
    "DCG = numerador / denominador\n",
    "DCG = DCG.sum(axis=1)\n",
    "\n",
    "iDCG = np.ones_like(DCG) * ideal\n",
    "nDCG = DCG / iDCG\n",
    "nDGC_version.append({'estructura': v, 'performance': nDCG.mean(), 'performance_puntual': nDCG})\n",
    "print(v)\n",
    "print(nDCG.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDCG = pd.DataFrame(nDCG, columns=(['last_ndcg']))\n",
    "NDCG.to_csv('last_ndcg8.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_TEST.to_csv('y_test8.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERADOR = pd.DataFrame(numerador, columns=['puntaje'+str(i) for i in range(10)])\n",
    "NUMERADOR.to_csv('last_numerador8.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDGC = pd.DataFrame(nDGC_version)\n",
    "NDGC.to_csv('ndgc_29-11-20_v1.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mercado visitado.\n",
    "DFF_PRED = pd.read_csv('dff_pred.csv', sep=';')\n",
    "mket_pred = np.array(DFF_PRED['mercado'])\n",
    "DMV_PRED = pd.read_csv('dmv_pred.csv', sep=';')\n",
    "dom_pred = np.array(DMV_PRED['vdomain']).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Clusters.\n",
    "clusters = pd.read_csv('clusters_reloaded.csv', sep=';')\n",
    "train_test = pd.read_csv('meli_segment_v2.csv', sep=';')\n",
    "clusters = pd.concat([clusters['cs32'], train_test], axis=1)\n",
    "clusters = clusters.loc[clusters['segment'] == 'test']\n",
    "cluster_pred = np.array(clusters['cs32']).astype('int32')\n",
    "cl_pred = np.unique(cluster_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Trampa cluster.\n",
    "clusters = pd.read_csv('dfs_pred.csv', sep=';')\n",
    "clusters['segmento'] = 0\n",
    "clusters.loc[clusters['v_len'] != 0, 'segmento'] = 1\n",
    "cluster_pred1 = np.array(clusters['segmento']).astype('int32')\n",
    "cl_pred1 = np.unique(cluster_pred1, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d8509d8ff2494ba10fbc1d06b8906a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=56), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#chosen_predictors = ['dim_bc',\n",
    "#                     'dim_liv',\n",
    "#                     'dim_miv',\n",
    "#                     'dim_opro_13',\n",
    "#                     'dim_ocat_16',\n",
    "#                     'dim_scat_31',\n",
    "#                     'dim_spro_13',\n",
    "#                     'dim_sdom_31',\n",
    "#                     'dim_tbd',\n",
    "#                     'dim_tbd2',\n",
    "#                     'dim_tbc',\n",
    "#                     'dim_tbc2',\n",
    "#                     'dim_tbp',\n",
    "#                     'dim_tbp2',\n",
    "#                     'dim_vc'] \n",
    "\n",
    "PRED_PRED, pred_pred = load_chosen_predictors_pred('C:/data/meli_challenge/predictors_pred', chosen_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca1ac0e230148f08872a69f6c511087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=177070), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicción final optimizada.\n",
    "k = 10\n",
    "    \n",
    "y_pred = []\n",
    "for i in tqdm(range(mket_pred.size)):\n",
    "    ccluster = cluster_pred[i]\n",
    "    cdom = dom_pred[i]\n",
    "    cmket = mket_pred[i]\n",
    "    if ccluster in list(inventario):\n",
    "        v = inventario[ccluster]['v_desc']\n",
    "    else:\n",
    "        alt_cluster = [x for x in list(inventario) if abs(x - ccluster) == min([abs(x - ccluster) for x in list(inventario)])][0]\n",
    "        v = inventario[alt_cluster]['v_desc']\n",
    "    for j, f in enumerate(v):\n",
    "        cref = grilla[ccluster][f]\n",
    "        citems = pred_pred[f][i]\n",
    "        mask = (cref > 0) & (citems >= 0)\n",
    "        cref = cref[mask]\n",
    "        citems = citems[mask]\n",
    "        if j == 0:\n",
    "            ranks = cref\n",
    "            items = citems\n",
    "        else:\n",
    "            ranks = np.concatenate([ranks, cref])\n",
    "            items = np.concatenate([items, citems])\n",
    "    y_hat = list(get_y_hat(items, ranks)[::-1])\n",
    "    if len(y_hat) < k:\n",
    "        size = k - len(y_hat)\n",
    "        ext = list(gen_sales(y_hat, cdom, cmket)[:size])\n",
    "        y_hat.extend(ext)\n",
    "        if len(y_hat) < k:\n",
    "            size = k - len(y_hat)\n",
    "            if cmket == 1:\n",
    "                ext = [x for x in top_mex if x not in y_hat][:size]\n",
    "            else:\n",
    "                ext = [x for x in top_brs if x not in y_hat][:size]\n",
    "            y_hat.extend(ext)\n",
    "    y_pred.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export.\n",
    "Y_PRED=pd.DataFrame(y_pred)\n",
    "Y_PRED.to_csv('submission_n25.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
