{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ezequiel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import.\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import unicodedata\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.text import one_hot\n",
    "from ast import literal_eval\n",
    "\n",
    "def jl_to_list(fname):\n",
    "    output = []\n",
    "    with gzip.open(fname, 'rb') as f:\n",
    "        for line in f:\n",
    "            output.append(json.loads(line))\n",
    "    return output\n",
    "\n",
    "def load_item_data(all_itms = False):\n",
    "    ITEM_DATA = pd.read_csv('item_data.csv', sep=';')\n",
    "    fields = ['item_id', 'domain_id', 'product_id', 'category_id', 'price', 'price_cluster', 'condition', 'mexico']\n",
    "    m = {}\n",
    "    for column in tqdm(fields):\n",
    "         m[column] = list(ITEM_DATA[column])\n",
    "    metadata = {}\n",
    "    for i, j in tqdm(enumerate(m['item_id'])):\n",
    "        metadata[j] = {}\n",
    "        for column in fields: \n",
    "            metadata[j].update({column: m[column][i]})\n",
    "    if all_itms:\n",
    "        all_items = list(metadata)\n",
    "    else:\n",
    "        all_items = []\n",
    "    return metadata, all_items\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return unicodedata.normalize('NFKD', s).encode('ASCII', 'ignore')\n",
    "\n",
    "def searchs(row):\n",
    "    return ([ev['event_info'] for ev in row['user_history'] if ev['event_type']=='search'])\n",
    "\n",
    "def process_unicode_str(s):\n",
    "    s = unicode_to_ascii(s).decode(\"utf-8\") \n",
    "    return s.replace(',', ' ').strip().upper()\n",
    "\n",
    "process_unicode_str_v = np.vectorize(process_unicode_str)\n",
    "\n",
    "def token_palabra(s, n, l):\n",
    "    if n < l:\n",
    "        return word_tokenize(s)[n]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "token_palabra_v = np.vectorize(token_palabra, excluded=['n'])\n",
    "\n",
    "def len_title(s):\n",
    "    return len(word_tokenize(s))\n",
    "\n",
    "len_title_v = np.vectorize(len_title)\n",
    "\n",
    "def split_list(L):\n",
    "    words = []\n",
    "    if len(L) > 0 :\n",
    "        for l in L:\n",
    "            for s in l.split():\n",
    "                words.append(s)\n",
    "    words = set(words)\n",
    "    s = ''\n",
    "    for w in words:\n",
    "        s += w + ' '\n",
    "    return s[:-1]\n",
    "\n",
    "def words_to_int(s, wl):\n",
    "    return one_hot(s, wl)\n",
    "\n",
    "words_to_int_v = np.vectorize(words_to_int)\n",
    "\n",
    "def words_to_int_l(S, wl):\n",
    "    return [words_to_int(s, wl) for s in S]\n",
    "\n",
    "def words_to_int2(s, wl):\n",
    "    return str(one_hot(s, wl))\n",
    "\n",
    "words_to_int2_v = np.vectorize(words_to_int2)\n",
    "\n",
    "def ranking_by_search(s,P):\n",
    "    dicc = {}\n",
    "    for w in s:\n",
    "        if w in P:\n",
    "            dicc = {key: dicc.get(key, 0) + P[w].get(key, 0) for key in set(dicc) | set(P[w])}\n",
    "    return dicc\n",
    "\n",
    "#Se requiere una versión que restrinja por mercado.\n",
    "#Y otra que limpie la endogeneidad. Sino la va a sobrevaluar.\n",
    "def join_rankings(S, P):\n",
    "    dicc = {}\n",
    "    for i, s in enumerate(S):\n",
    "        d = ranking_by_search(s, P)\n",
    "        dicc = {key: dicc.get(key, 0) + d.get(key, 0) for key in set(dicc) | set(d)}\n",
    "    return [x[0] for x in sorted(dicc.items(), key=lambda item: item[1], reverse=True)][:10]\n",
    "\n",
    "def join_rankings_s(S, P):\n",
    "    dicc = {}\n",
    "    for i, s in enumerate(S):\n",
    "        d = ranking_by_search(s, P)\n",
    "        dicc = {key: dicc.get(key, 0) + d.get(key, 0) for key in set(dicc) | set(d)}\n",
    "    return str([x[0] for x in sorted(dicc.items(), key=lambda item: item[1], reverse=True)][:10])\n",
    "\n",
    "join_rankings_v = np.vectorize(join_rankings_s, excluded=['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_DATA = pd.read_csv('item_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = np.array(ITEM_DATA['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ninja = process_unicode_str_v(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuenta de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "linyera = len_title_v(ninja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "crayon = np.empty([title.size, linyera.max()], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec490b7ef9c499d806bcca7004368c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(crayon.shape[1])):\n",
    "    crayon[:,i] = token_palabra_v(ninja, i, linyera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRAYON = pd.DataFrame(crayon, columns=['word'+str(i) for i in range(crayon.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRAYON.to_csv('matrix_of_words_titles.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#CRAYON = pd.read_csv('matrix_of_words_titles.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos de búsquedas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_train = pd.read_csv('searchs_train_uq.csv', sep=';')\n",
    "ss_test = pd.read_csv('searchs_test_uq.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_train['searchs_train_uq'] = ss_train['searchs_train_uq'].apply(lambda x: literal_eval(x))\n",
    "ss_test['searchs_test_uq'] = ss_test['searchs_test_uq'].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_train['words'] = ss_train['searchs_train_uq'].apply(split_list)\n",
    "ss_test['words'] = ss_test['searchs_test_uq'].apply(split_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retorna a cuenta de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_train = np.array(ss_train['words'])\n",
    "s_test = np.array(ss_test['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e62dfdd86844569b94dfdaa7dc2018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=413163), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "words_train = []\n",
    "for r in tqdm(range(len(ss_train))):\n",
    "    words_train.extend(ss_train['words'].iloc[r].split())\n",
    "    \n",
    "words_train = set(words_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d127c98475164f31b39744b3c0d27829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=177070), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "words_test = []\n",
    "for r in tqdm(range(len(ss_test))):\n",
    "    words_test.extend(ss_test['words'].iloc[r].split())\n",
    "    \n",
    "words_test = set(words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121002"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77049"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = words_train.intersection(words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51474"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words_train.union(words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c33c86da32e472488433abee44d76e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(crayon.shape[1])):\n",
    "    if i == 0:\n",
    "        words_title = set(np.unique(crayon[:,i]))\n",
    "    else:\n",
    "        words_title = words_title.union(set(np.unique(crayon[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-aac4196589fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwords_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrayon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[0mFind\u001b[0m \u001b[0mthe\u001b[0m \u001b[0munique\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignoring\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \"\"\"\n\u001b[1;32m--> 304\u001b[1;33m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[0moptional_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#words_title = set(np.unique(crayon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La primera vez que hice este conjunto estaba mal. Originalmente len(words)==548326. Ahora resultan 562373.\n",
    "#words = words_train.union(words_title)\n",
    "words = words.union(words_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562373"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_len = len(words) + 500 - 326\n",
    "w_len = len(words) + 600 - 373"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retorno a confección de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "busquedas = pd.concat([ss_train['searchs_train_uq'], ss_test['searchs_test_uq']], axis=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "busquedas = busquedas.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "busquedas.columns = ['index', 'searchs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>searchs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[RELOGIO SMARTWATCH]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[DESMAMADEIRA ELETRICA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[RADIOBOSS, SOUND FORGE, SOUND FORGE PLUGINS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[AMAZFIT BIP, AMAZFIT BIPAMAZFIT BIP, AMAZFIT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590228</td>\n",
       "      <td>177065</td>\n",
       "      <td>[ENDER 3, MOTOR TUBULAR PERSIANA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590229</td>\n",
       "      <td>177066</td>\n",
       "      <td>[CAJA PORTAOBJETOS LABORATORIO, FILTRO AGUA, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590230</td>\n",
       "      <td>177067</td>\n",
       "      <td>[CONTROLE CELULAR, FANTASIAS HALLOWEEN CORINGA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590231</td>\n",
       "      <td>177068</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590232</td>\n",
       "      <td>177069</td>\n",
       "      <td>[20 TOMADAS INTERRUPTORES ILUMI, BLUSA CREPE F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                            searchs\n",
       "0            0                               [RELOGIO SMARTWATCH]\n",
       "1            1                            [DESMAMADEIRA ELETRICA]\n",
       "2            2                                                 []\n",
       "3            3      [RADIOBOSS, SOUND FORGE, SOUND FORGE PLUGINS]\n",
       "4            4  [AMAZFIT BIP, AMAZFIT BIPAMAZFIT BIP, AMAZFIT ...\n",
       "...        ...                                                ...\n",
       "590228  177065                  [ENDER 3, MOTOR TUBULAR PERSIANA]\n",
       "590229  177066  [CAJA PORTAOBJETOS LABORATORIO, FILTRO AGUA, F...\n",
       "590230  177067    [CONTROLE CELULAR, FANTASIAS HALLOWEEN CORINGA]\n",
       "590231  177068                                                 []\n",
       "590232  177069  [20 TOMADAS INTERRUPTORES ILUMI, BLUSA CREPE F...\n",
       "\n",
       "[590233 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "busquedas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Con este esquema llegué a 51256 palabras coincidentes.\n",
    "#La segunda vez fueron 51162 palabras coincidentes.\n",
    "w_len = 562373 + 600 - 373\n",
    "busquedas['searchs_int'] = busquedas['searchs'].apply(words_to_int_l, args=[w_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss_test['searchs_int'] = ss_test['searchs_test_uq'].apply(words_to_int_l, args=[w_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss_train['searchs_int'] = ss_train['searchs_train_uq'].apply(words_to_int_l, args=[w_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_int_train = []\n",
    "for S in list(busquedas['searchs_int'][:413163]):\n",
    "    for s in S:\n",
    "        for w in s:\n",
    "            words_int_train.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_int_test = []\n",
    "for S in list(busquedas['searchs_int'][-177070:]):\n",
    "    for s in S:\n",
    "        for w in s:\n",
    "            words_int_test.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_int_train = set(words_int_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_int_test = set(words_int_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51162"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_int_test.intersection(words_int_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_train = pd.concat([ss_train, busquedas['searchs_int'][:413163]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = busquedas['searchs_int'][-177070:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_test = pd.concat([ss_test, temp['searchs_int']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "IB = pd.read_csv('ib.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_train = pd.concat([ss_train, IB], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retorno a títulos de ítems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Controlar que las palabras aquí estén puestas con criterio. Sino 36 y 12 pueden estar mal asignados y habría que cambiar la estrategia.\n",
    "turtle = words_to_int2_v(ninja, w_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c59ed4065d4a7987a1ef3d16be5bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2102277), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word_int_titles = []\n",
    "for i in tqdm(list(turtle)):\n",
    "    for j in literal_eval(i):\n",
    "        word_int_titles.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270621"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_int_titles = set(word_int_titles)\n",
    "len(word_int_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89687\n"
     ]
    }
   ],
   "source": [
    "print(len(word_int_titles.intersection(words_int_train)))\n",
    "print(len(word_int_titles.intersection(words_int_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "TURTLE = pd.DataFrame(turtle, columns=['encoded_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_DATA = pd.concat([ITEM_DATA, TURTLE], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_train = pd.merge(ss_train, \n",
    "                 ITEM_DATA.loc[:,['item_id', 'encoded_title', 'title']], \n",
    "                 how='left', \n",
    "                 left_on='ib', \n",
    "                 right_on='item_id').drop(columns=['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_train.to_csv('ninja.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_test.to_csv('estenio.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss_train = pd.read_csv('ninja.csv', sep=';')\n",
    "#ss_train['searchs_int'] = ss_train['searchs_int'].apply(lambda x: literal_eval(x))\n",
    "#ss_test = pd.read_csv('estenio.csv', sep=';')\n",
    "#ss_test['searchs_int'] = ss_test['searchs_int'].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esto hay que aplicarlo sí o sí porque viene de la función vectorial como str.\n",
    "ss_train['encoded_title'] = ss_train['encoded_title'].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b220d7daedd46778f1a43533b0718aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=413163), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Diccionario de puntaje de palabras.\n",
    "ss_train['puntaje'] = None\n",
    "for i in tqdm(range(len(ss_train))):\n",
    "    ctitle = ss_train['encoded_title'].iloc[i]\n",
    "    dicc = {}\n",
    "    for s in ss_train['searchs_int'].iloc[i]:\n",
    "        for w in s:\n",
    "            if w == ctitle[0]:\n",
    "                dicc.update({w: 36})\n",
    "            elif w in ctitle:\n",
    "                dicc.update({w: 12})\n",
    "            else:\n",
    "                dicc.update({w: 1})\n",
    "    #Falla caveats.\n",
    "    ss_train['puntaje'][i] = dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_train.to_csv('ninja_con_puntaje.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss_train = pd.read_csv('ninja_con_puntaje.csv', sep=';')\n",
    "#ss_train['puntaje'] = ss_train['puntaje'].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b0f7d2928a47dfbb285d12d31933ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=64928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "puntajes = {}\n",
    "for i in tqdm(list(ss_train['ib'].value_counts().index)):\n",
    "    compras = ss_train.loc[ss_train['ib'] == i, 'puntaje']\n",
    "    compras = compras.reset_index()\n",
    "    dicc = {}\n",
    "    for j in range(len(compras)):\n",
    "        for k in compras['puntaje'].iloc[j]:\n",
    "            if k in dicc:\n",
    "                dicc[k] = dicc[k] + compras['puntaje'].iloc[j][k]\n",
    "            else:\n",
    "                dicc[k] = compras['puntaje'].iloc[j][k]\n",
    "    puntajes.update({i: dicc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb330686e17e473db0cebb6390087800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=64928), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "palabras = {}\n",
    "for i in tqdm(puntajes):\n",
    "    for j in puntajes[i]:\n",
    "        if j in palabras:\n",
    "            palabras[j].update({i: puntajes[i][j]})\n",
    "        else:\n",
    "            palabras[j] = {i: puntajes[i][j]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38db86b02c548ee81e5b70aba117f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=413163), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3874624ce14f4d7f8d79b1b169d0a171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=177070), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 2h 39min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Tarda dos horas en terminar.\n",
    "pred = []\n",
    "k = 10\n",
    "for i in tqdm(list(ss_train['searchs_int'])):\n",
    "    temp = join_rankings(i, palabras)\n",
    "    if len(temp) < k:\n",
    "        temp.extend([-1] * (k - len(temp)))\n",
    "    pred.append(temp)\n",
    "    \n",
    "pred_pred = []\n",
    "k = 10\n",
    "for i in tqdm(list(ss_test['searchs_int'])):\n",
    "    temp = join_rankings(i, palabras)\n",
    "    if len(temp) < k:\n",
    "        temp.extend([-1] * (k - len(temp)))\n",
    "    pred_pred.append(temp)\n",
    "    \n",
    "DIM_SSS = pd.DataFrame(pred, columns=['pred'+str(i) for i in range(10)])\n",
    "DIM_SSS.to_csv('dim_sss.csv', index=False, sep=';')\n",
    "\n",
    "DIM_PRED_SSS = pd.DataFrame(pred_pred, columns=['pred'+str(i) for i in range(10)])\n",
    "DIM_PRED_SSS.to_csv('dim_pred_sss.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(DIM_SSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array(DIM_PRED_SSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8226878979966744"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Valor anteior: 0.8010475284572917.\n",
    "a[a != -1].size / a.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8232614220364828"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Valor anterior: 0.8012994860789519.\n",
    "b[b != -1].size / b.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
